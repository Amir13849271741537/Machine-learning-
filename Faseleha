در یادگیری ماشین (Machine Learning)، فاصله‌ها (Distances or Similarity Measures) نقش مهمی در مقایسه‌ی داده‌ها، خوشه‌بندی (Clustering)، طبقه‌بندی (Classification) و تحلیل شباهت دارند.

در ادامه، انواع مهم‌ترین معیارهای فاصله را به‌صورت دسته‌بندی‌شده با فرمول و کاربرد توضیح می‌دهم 1. فاصله اقلیدسی (Euclidean Distance)

رایج‌ترین نوع فاصله در یادگیری ماشین است.

فرمول:
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}

کاربرد:
 • الگوریتم KNN (K-Nearest Neighbors)
 • K-Means Clustering
 • اندازه‌گیری شباهت در فضاهای هندسی
توضیح: فاصله‌ی مستقیم بین دو نقطه (مثل خط‌کش در فضای چندبعدی).

2. فاصله منهتن (Manhattan Distance)

به آن L1 distance یا City Block Distance هم می‌گویند.
فرمول:
d(x, y) = \sum_{i=1}^{n} |x_i - y_i|
کاربرد:
 • در داده‌هایی با مقیاس شبکه‌ای (مثل مختصات خیابانی)
 • در الگوریتم‌هایی که به نویز حساس‌اند کمتر از اقلیدسی آسیب می‌بیند
توضیح: فاصله‌ای است که اگر در شهر به صورت “چهارراه به چهارراه” حرکت کنی طی می‌کنی.

3. فاصله مینکوفسکی (Minkowski Distance)
شکل کلی‌تر اقلیدسی و منهتن است.
فرمول:
d(x, y) = \left(\sum_{i=1}^{n} |x_i - y_i|^p \right)^{1/p}

کاربرد:
 • وقتی بخواهی بین فاصله اقلیدسی و منهتن سوییچ کنی:
 • اگر p = 1 → منهتن
 • اگر p = 2 → اقلیدسی
4. فاصله چبیشف (Chebyshev Distance)

حداکثر اختلاف بین مختصات دو نقطه.
فرمول:
d(x, y) = \max_i |x_i - y_i|
 کاربرد:
 • در بازی‌ها و شبکه‌های گریدی (grid)
 • وقتی بخواهی “دورترین تفاوت” را بسنجی
5. فاصله کسینوسی (Cosine Distance)
به‌جای فاصله‌ی مستقیم، زاویه‌ی بین دو بردار را می‌سنجد.
فرمول شباهت کسینوسی:
\text{similarity}(x, y) = \frac{x \cdot y}{||x|| \, ||y||}
فاصله کسینوسی:
d(x, y) = 1 - \text{similarity}(x, y)
کاربرد:
 • در پردازش زبان طبیعی (NLP)
 • در سیستم‌های پیشنهاددهنده (Recommendation Systems)
 • در داده‌های برداری (مثل TF-IDF در متون)
توضیح: اگر جهت دو بردار مشابه باشد (زاویه کم باشد)، فاصله‌شان کم است حتی اگر اندازه‌شان متفاوت باشد.
6. فاصله ماهالانوبیس (Mahalanobis Distance)
فاصله‌ای است که همبستگی بین ویژگی‌ها را هم در نظر می‌گیرد.
فرمول:
d(x, y) = \sqrt{(x - y)^T S^{-1} (x - y)}
که در آن S ماتریس کوواریانس داده‌ها است. کاربرد:
 • در تشخیص ناهنجاری (Outlier Detection)
 • در داده‌هایی که ویژگی‌ها همبسته‌اند
 • در یادگیری آماری
7. فاصله همینگ (Hamming Distance)
تعداد موقعیت‌هایی که دو رشته در آن‌ها با هم فرق دارند.
 فرمول:
d(x, y) = \sum_{i=1}^{n} [x_i \neq y_i]
کاربرد:
 • در داده‌های دسته‌ای یا دودویی (Binary / Categorical)
 • در رمزگذاری، ژنتیک، و یادگیری ماشین گسسته
 مثال:
بین 1011101 و 1001001 → فاصله همینگ = 2
8. فاصله Jaccard
برای مجموعه‌ها یا داده‌های دودویی به‌کار می‌رود.
فرمول:
d(x, y) = 1 - \frac{|x \cap y|}{|x \cup y|}
کاربرد:
 • در تحلیل شباهت مجموعه‌ها
 • در داده‌های متنی یا برچسبی
